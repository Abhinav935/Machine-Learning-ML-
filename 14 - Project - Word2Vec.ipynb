{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b13b1e",
   "metadata": {},
   "source": [
    "# Project: Create a Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b981a3",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a11b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c3250",
   "metadata": {},
   "source": [
    "### Step 2: Download stopwords\n",
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e25497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/adel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/adel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012c520",
   "metadata": {},
   "source": [
    "### Step 3: Read content and sentinize\n",
    "- Initialize an empty list called **all_sentences**\n",
    "- For each filename in **'files/holmes'**:\n",
    "    - HINT: Use **os.listdir(...)** ([docs](https://docs.python.org/3/library/os.html#os.listdir))\n",
    "- Open the file and read the content and convert to lowercase and apply **nltk.sent_tokenize** on content.\n",
    "    - Use **lower()** on content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8769c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for filename in os.listdir('files/holmes'):\n",
    "    with open(f'files/holmes/{filename}') as f:\n",
    "        content = f.read()\n",
    "        all_sentences += nltk.sent_tokenize(content.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ea3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e4362c",
   "metadata": {},
   "source": [
    "### Step 4: Tokenize each sentence\n",
    "- Get all words by applying **nltk.word_tokenize** on them and assign the result to **all_words**\n",
    "    - HINT: Use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958c041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70e6a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', '``', 'gloria', 'scott', \"''\", '``', 'i', 'have', 'some', 'papers']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959014e8",
   "metadata": {},
   "source": [
    "### Step 5: Remove all stop words\n",
    "- Use **stopwords.words('english')** to filter all the words in **all_words**\n",
    "    - HINT: iterate over the length of **all_words**, for each index use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b4335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40656352",
   "metadata": {},
   "source": [
    "### Step 6: Remove special characters\n",
    "- Iterate over items in **all_words** to remove words with special characters\n",
    "    - HINT: Use **isalpha()** ([doc](https://docs.python.org/3/library/stdtypes.html#str.isalpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c8700b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1768ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8bca8cf",
   "metadata": {},
   "source": [
    "### Step 7: Install gensim and python-Levenshtein\n",
    "- Run the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43059c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/adel/miniconda3/envs/ML_DS/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/adel/miniconda3/envs/ML_DS/lib/python3.9/site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/adel/miniconda3/envs/ML_DS/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/adel/miniconda3/envs/ML_DS/lib/python3.9/site-packages (from gensim) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e95bb6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /home/adel/miniconda3/envs/ML_DS/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: setuptools in /home/adel/miniconda3/envs/ML_DS/lib/python3.9/site-packages (from python-Levenshtein) (62.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a94c5",
   "metadata": {},
   "source": [
    "### Step 8: Import another library\n",
    "- Run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8986ec55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dad3d2",
   "metadata": {},
   "source": [
    "### Step 9: Create a model\n",
    "- Use **Word2Vec** on **all_words**\n",
    "    - Use **min_count=2** : Ignores all words with total frequency lower than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9074eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ade815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1da22183",
   "metadata": {},
   "source": [
    "### Step 10: Find distances\n",
    "- Try to run **model.wv.distance('holmes', 'watson')**\n",
    "- Try to run **model.wv.distance('holmes', 'water')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ebb8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005608201026916504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('holmes', 'watson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cd39bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012046098709106445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('holmes', 'water')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26dd8c",
   "metadata": {},
   "source": [
    "### Step 11: Find closests words\n",
    "- Get all the words\n",
    "    - HINT: **words = model.wv.index_to_key**\n",
    "- Implement a function **closets_words(word)**\n",
    "    - HINT: **distances = {w: model.wv.distance(word, w) for w in words}**\n",
    "    - HINT: **sorted(distances, key=lambda w: distances[w])[:15]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef88b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index_to_key\n",
    "\n",
    "def closets_words(word):\n",
    "    distances = {w: model.wv.distance(word, w) for w in words}\n",
    "    return sorted(distances, key=lambda w: distances[w])[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce5df3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holmes',\n",
       " 'friend',\n",
       " 'hand',\n",
       " 'made',\n",
       " 'without',\n",
       " 'eyes',\n",
       " 'turned',\n",
       " 'first',\n",
       " 'colonel',\n",
       " 'yet',\n",
       " 'must',\n",
       " 'quite',\n",
       " 'come',\n",
       " 'little',\n",
       " 'words']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closets_words('holmes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49dcfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
